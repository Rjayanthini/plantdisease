{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC8iN-41Qy_j"
      },
      "outputs": [],
      "source": [
        "%pip install torch==1.8.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchvision==0.9.0"
      ],
      "metadata": {
        "id": "Lu988s_sQ6yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torchaudio==0.8.0"
      ],
      "metadata": {
        "id": "44Owo352RObO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install --upgrade torch==1.8.0 torchvision==0.9.0 torchaudio===0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "1RsE2tnyRR0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pillow==8.2.0"
      ],
      "metadata": {
        "id": "CDNlLq8pRUYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install or upgrade PyTorch 1.8.0 and OnnxRuntime 1.8 for CPU-only.\n",
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install --upgrade onnxruntime==1.8.0\n",
        "!{sys.executable} -m pip install --upgrade onnx\n",
        "# !{sys.executable} -m pip install pillow"
      ],
      "metadata": {
        "id": "V1PZp1LjRXjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall Pillow\n"
      ],
      "metadata": {
        "id": "DOfMRCf8RaJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models, datasets, transforms as T\n",
        "mobilenet_v2 = models.mobilenet_v2(pretrained=True)"
      ],
      "metadata": {
        "id": "iRUEDv0yRc1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "image_height = 224\n",
        "image_width = 224\n",
        "x = torch.randn(1, 3, image_height, image_width, requires_grad=True)\n",
        "torch_out = mobilenet_v2(x)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(mobilenet_v2,              # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"mobilenet_v2_float.onnx\", # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=12,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output']) # the model's output names\n"
      ],
      "metadata": {
        "id": "txvA23gCRihm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import torch\n",
        "\n",
        "def preprocess_image(image_path, height, width, channels=3):\n",
        "    image = Image.open(image_path)\n",
        "    image = image.resize((width, height), Image.ANTIALIAS)\n",
        "    image_data = np.asarray(image).astype(np.float32)\n",
        "    image_data = image_data.transpose([2, 0, 1]) # transpose to CHW\n",
        "    mean = np.array([0.079, 0.05, 0]) + 0.406\n",
        "    std = np.array([0.005, 0, 0.001]) + 0.224\n",
        "    for channel in range(image_data.shape[0]):\n",
        "        image_data[channel, :, :] = (image_data[channel, :, :] / 255 - mean[channel]) / std[channel]\n",
        "    image_data = np.expand_dims(image_data, 0)\n",
        "    return image_data"
      ],
      "metadata": {
        "id": "XAclNx9BRjiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ImageNet labels\n",
        "!curl -o imagenet_classes.txt https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
        "\n",
        "# Read the categories\n",
        "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
        "    categories = [s.strip() for s in f.readlines()]"
      ],
      "metadata": {
        "id": "SYXhmpDiRl2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_fp32 = onnxruntime.InferenceSession(\"mobilenet_v2_float.onnx\")\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()\n",
        "\n",
        "def run_sample(session, image_file, categories):\n",
        "    output = session.run([], {'input':preprocess_image(image_file, image_height, image_width)})[0]\n",
        "    output = output.flatten()\n",
        "    output = softmax(output) # this is optional\n",
        "    top5_catid = np.argsort(-output)[:5]\n",
        "    for catid in top5_catid:\n",
        "        print(categories[catid], output[catid])\n",
        "\n",
        "run_sample(session_fp32, 'cat.jpg', categories)"
      ],
      "metadata": {
        "id": "weaFPchBRoHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType\n",
        "import os\n",
        "\n",
        "def preprocess_func(images_folder, height, width, size_limit=0):\n",
        "    image_names = os.listdir(images_folder)\n",
        "    if size_limit > 0 and len(image_names) >= size_limit:\n",
        "        batch_filenames = [image_names[i] for i in range(size_limit)]\n",
        "    else:\n",
        "        batch_filenames = image_names\n",
        "    unconcatenated_batch_data = []\n",
        "\n",
        "    for image_name in batch_filenames:\n",
        "        image_filepath = images_folder + '/' + image_name\n",
        "        image_data = preprocess_image(image_filepath, height, width)\n",
        "        unconcatenated_batch_data.append(image_data)\n",
        "    batch_data = np.concatenate(np.expand_dims(unconcatenated_batch_data, axis=0), axis=0)\n",
        "    return batch_data\n",
        "\n",
        "\n",
        "class MobilenetDataReader(CalibrationDataReader):\n",
        "    def __init__(self, calibration_image_folder):\n",
        "        self.image_folder = calibration_image_folder\n",
        "        self.preprocess_flag = True\n",
        "        self.enum_data_dicts = []\n",
        "        self.datasize = 0\n",
        "\n",
        "    def get_next(self):\n",
        "        if self.preprocess_flag:\n",
        "            self.preprocess_flag = False\n",
        "            nhwc_data_list = preprocess_func(self.image_folder, image_height, image_width, size_limit=0)\n",
        "            self.datasize = len(nhwc_data_list)\n",
        "            self.enum_data_dicts = iter([{'input': nhwc_data} for nhwc_data in nhwc_data_list])\n",
        "        return next(self.enum_data_dicts, None)"
      ],
      "metadata": {
        "id": "SYv6mgDyRqXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change it to your real calibration data set\n",
        "calibration_data_folder = \"calibration_imagenet\"\n",
        "dr = MobilenetDataReader(calibration_data_folder)\n",
        "\n",
        "quantize_static('mobilenet_v2_float.onnx',\n",
        "                'mobilenet_v2_uint8.onnx',\n",
        "                dr)\n",
        "\n",
        "print('ONNX full precision model size (MB):', os.path.getsize(\"mobilenet_v2_float.onnx\")/(1024*1024))\n",
        "print('ONNX quantized model size (MB):', os.path.getsize(\"mobilenet_v2_uint8.onnx\")/(1024*1024))"
      ],
      "metadata": {
        "id": "QOw94gy4RtPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "session_quant = onnxruntime.InferenceSession(\"mobilenet_v2_uint8.onnx\")\n",
        "run_sample(session_quant, 'rose1.jpg', categories)"
      ],
      "metadata": {
        "id": "3Bk5DyS-Rv2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_quant = onnxruntime.InferenceSession(\"mobilenet_v2_uint8.onnx\")\n",
        "run_sample(session_quant, 'hddog.jpg', categories)"
      ],
      "metadata": {
        "id": "_-OdqkMCRyVb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}